{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from pickle import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "# import plotly.express as px\n",
    "from tensorflow.keras import layers\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import piq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain, Ytrain), (Xtest, Ytest) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "Xtrain = np.expand_dims(Xtrain,-1)\n",
    "Xtest = np.expand_dims(Xtest,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_pos(X, y, desp_h, desp_v):\n",
    "  X_big = np.zeros((X.shape[0],256,256,1))\n",
    "  X_big[:,114+desp_v:114+28+desp_v,114+desp_h:114+28+desp_h] = X[:,:,:]\n",
    "  return X_big.astype(np.float32), y.astype(np.int32)\n",
    "\n",
    "def _fixup_shape(images, labels):\n",
    "    images.set_shape((256,256,256,1))\n",
    "    labels.set_shape((256,))\n",
    "    return images, labels\n",
    "\n",
    "dst_train = tf.data.Dataset.from_tensor_slices((Xtest, Ytest)).batch(256, drop_remainder=True)\n",
    "\n",
    "var_pos_loquesea = partial(var_pos,desp_h = 0, desp_v = 0)\n",
    "\n",
    "def tf_function(x,y):\n",
    "  return tf.numpy_function(var_pos_loquesea, [x,y], (tf.float32, tf.int32))\n",
    "\n",
    "\n",
    "dst_big = dst_train.map(tf_function).map(_fixup_shape)\n",
    "\n",
    "Xtrain_big_VGG = dst_big.map(lambda x,y: (tf.keras.applications.vgg16.preprocess_input(\n",
    "    tf.image.grayscale_to_rgb(tf.convert_to_tensor(x)), data_format=None\n",
    "),y) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 221s 6s/step - loss: 2.1710 - accuracy: 0.6291\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 220s 6s/step - loss: 0.3060 - accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 219s 6s/step - loss: 0.1717 - accuracy: 0.9475\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 219s 6s/step - loss: 0.1239 - accuracy: 0.9628\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 220s 6s/step - loss: 0.1004 - accuracy: 0.9710\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 216s 5s/step - loss: 0.0846 - accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 216s 5s/step - loss: 0.0728 - accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 218s 6s/step - loss: 0.0632 - accuracy: 0.9837\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 218s 6s/step - loss: 0.0549 - accuracy: 0.9865\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 218s 6s/step - loss: 0.0480 - accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "VGG16 = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256,256,3),\n",
    ")\n",
    "\n",
    "for capa in VGG16.layers:\n",
    "    capa.trainable = False\n",
    "\n",
    "    model_VGG16 = tf.keras.Sequential([\n",
    "    VGG16,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model_VGG16.compile(optimizer = \"adam\", metrics=[\"accuracy\"], loss = \"sparse_categorical_crossentropy\")\n",
    "history = model_VGG16.fit(Xtrain_big_VGG, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_VGG16.save('./model_VGG16.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 212s 5s/step - loss: 1.5530 - accuracy: 0.5291\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 209s 5s/step - loss: 0.9053 - accuracy: 0.7481\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 213s 5s/step - loss: 0.7398 - accuracy: 0.7911\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 214s 5s/step - loss: 0.6520 - accuracy: 0.8127\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 214s 5s/step - loss: 0.5948 - accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "39/39 [==============================] - 215s 5s/step - loss: 0.5529 - accuracy: 0.8382\n",
      "Epoch 7/10\n",
      "39/39 [==============================] - 213s 5s/step - loss: 0.5204 - accuracy: 0.8482\n",
      "Epoch 8/10\n",
      "39/39 [==============================] - 212s 5s/step - loss: 0.4940 - accuracy: 0.8536\n",
      "Epoch 9/10\n",
      "39/39 [==============================] - 211s 5s/step - loss: 0.4722 - accuracy: 0.8623\n",
      "Epoch 10/10\n",
      "39/39 [==============================] - 213s 5s/step - loss: 0.4536 - accuracy: 0.8669\n"
     ]
    }
   ],
   "source": [
    "Xtrain_big_RN = dst_big.map(lambda x,y: (tf.keras.applications.resnet50.preprocess_input(\n",
    "    tf.image.grayscale_to_rgb(tf.convert_to_tensor(x)), data_format=None),y) )\n",
    "\n",
    "ResNet50 = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256,256,3)\n",
    ")\n",
    "\n",
    "for capa in ResNet50.layers:\n",
    "    capa.trainable = False\n",
    "\n",
    "model_ResNet50 = tf.keras.Sequential([\n",
    "    ResNet50,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model_ResNet50.compile(optimizer = \"adam\", metrics=[\"accuracy\"], loss = \"sparse_categorical_crossentropy\")\n",
    "\n",
    "history = model_ResNet50.fit(Xtrain_big_RN, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ResNet50.save('./model_ResNet50.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
